{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fd3fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:58.540250Z",
     "start_time": "2025-05-17T11:32:58.537196Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193af2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.312230Z",
     "start_time": "2025-05-17T11:32:58.541766Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "import bottleneck as bn\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1d956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.315881Z",
     "start_time": "2025-05-17T11:32:59.313215Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c0343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.327073Z",
     "start_time": "2025-05-17T11:32:59.316988Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = # dataset name\n",
    "\n",
    "if dataset not in ['ml20m', 'netflix', 'msd', 'amazon-book', 'yelp2018', 'gowalla']:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c23628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.332166Z",
     "start_time": "2025-05-17T11:32:59.327691Z"
    }
   },
   "outputs": [],
   "source": [
    "if dataset == 'ml20m':\n",
    "    params = {'bs_min': 6.79, 'bs_vel': 0.24,\n",
    "              '-nu': 0.3,\n",
    "              'γ_st %': -0.28, 'γ_vel': 0.0389,\n",
    "              'n_hid': 2048, 'n_epochs': 100}\n",
    "    \n",
    "if dataset == 'netflix':\n",
    "    params = {'bs_min': 10, 'bs_vel': 0.166,\n",
    "              '-nu': 0.175,\n",
    "              'γ_st %': 1.4, 'γ_vel': 0.0325,\n",
    "              'n_hid': 2048, 'n_epochs': 100}\n",
    "\n",
    "if dataset == 'msd':\n",
    "    params = {'bs_min': 16, 'bs_vel': 0.2,\n",
    "              '-nu': 0.1,\n",
    "              'γ_st %': 1.2, 'γ_vel': 0.05,\n",
    "              'n_hid': 4096, 'n_epochs': 100}\n",
    "\n",
    "if dataset == 'amazon-book':\n",
    "    params = {'bs_min': 13.899, 'bs_vel': 0.271,\n",
    "              '-nu': 0.302,\n",
    "              'γ_st %': -0.169, 'γ_vel': 0.009,\n",
    "              'n_hid': 4096, 'n_epochs': 100}\n",
    "\n",
    "if dataset == 'yelp2018':\n",
    "    params = {'bs_min': 16, 'bs_vel': 0.15,\n",
    "              '-nu': 0.096,\n",
    "              'γ_st %': 0.05, 'γ_vel': 0.0026,\n",
    "              'n_hid': 1024, 'n_epochs': 100}\n",
    "\n",
    "if dataset == 'gowalla':\n",
    "    params = {'bs_min': 14.66, 'bs_vel': 0.317,\n",
    "              '-nu': 0.450,\n",
    "              'γ_st %': -2.079, 'γ_vel': 0.0427,\n",
    "              'n_hid': 4096, 'n_epochs': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c597fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.473824Z",
     "start_time": "2025-05-17T11:32:59.332843Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = load_npz('data/' + dataset + '/train_data.npz')\n",
    "valid_in_data = load_npz('data/' + dataset + '/valid_in_data.npz')\n",
    "valid_out_data = load_npz('data/' + dataset + '/valid_out_data.npz')\n",
    "test_in_data = load_npz('data/' + dataset + '/test_in_data.npz')\n",
    "test_out_data = load_npz('data/' + dataset + '/test_out_data.npz')\n",
    "\n",
    "n_users, n_items = train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476e951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T23:53:10.298846Z",
     "start_time": "2025-05-16T23:53:10.296511Z"
    }
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fc33c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.478668Z",
     "start_time": "2025-05-17T11:32:59.474832Z"
    }
   },
   "outputs": [],
   "source": [
    "def ndcg(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG\n",
    "\n",
    "\n",
    "def recall(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0050b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.486260Z",
     "start_time": "2025-05-17T11:32:59.479511Z"
    }
   },
   "outputs": [],
   "source": [
    "if dataset in ['ml20m', 'netflix', 'msd']:\n",
    "    metrics = [{'metric': ndcg, 'k': 100}]\n",
    "    test_metrics = [{'metric': ndcg, 'k': 100}, {'metric': recall, 'k': 20}, {'metric': recall, 'k': 50}]\n",
    "    \n",
    "if dataset in ['amazon-book', 'yelp2018', 'gowalla']:\n",
    "    metrics = [{'metric': ndcg, 'k': 20}]\n",
    "    test_metrics = [{'metric': ndcg, 'k': 20}, {'metric': recall, 'k': 20}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce799650",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f18d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.491444Z",
     "start_time": "2025-05-17T11:32:59.486966Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(batch_size, device, data_in, data_out=None, shuffle=False, samples_perc_per_epoch=1):\n",
    "    assert 0 < samples_perc_per_epoch <= 1\n",
    "    \n",
    "    total_samples = data_in.shape[0]\n",
    "    samples_per_epoch = int(total_samples * samples_perc_per_epoch)\n",
    "    \n",
    "    if shuffle:\n",
    "        idxlist = np.arange(total_samples)\n",
    "        np.random.shuffle(idxlist)\n",
    "        idxlist = idxlist[:samples_per_epoch]\n",
    "    else:\n",
    "        idxlist = np.arange(samples_per_epoch)\n",
    "    \n",
    "    for st_idx in range(0, samples_per_epoch, batch_size):\n",
    "        end_idx = min(st_idx + batch_size, samples_per_epoch)\n",
    "        idx = idxlist[st_idx:end_idx]\n",
    "\n",
    "        yield Batch(device, idx, data_in, data_out)\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, device, idx, data_in, data_out=None):\n",
    "        self._device = device\n",
    "        self._idx = idx\n",
    "        self._data_in = data_in\n",
    "        self._data_out = data_out\n",
    "    \n",
    "    def get_idx(self):\n",
    "        return self._idx\n",
    "    \n",
    "    def get_idx_to_dev(self):\n",
    "        return torch.LongTensor(self.get_idx()).to(self._device)\n",
    "        \n",
    "    def get_ratings(self, is_out=False):\n",
    "        data = self._data_out if is_out else self._data_in\n",
    "        return data[self._idx]\n",
    "    \n",
    "    def get_ratings_to_dev(self, is_out=False):\n",
    "        return torch.Tensor(\n",
    "            self.get_ratings(is_out).toarray()\n",
    "        ).to(self._device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1443b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45161dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.498501Z",
     "start_time": "2025-05-17T11:32:59.492710Z"
    }
   },
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_vis, n_hid, γ, nu, k=1):\n",
    "        super(RBM, self).__init__()\n",
    "        self.b = nn.Parameter(torch.randn(1, n_vis))\n",
    "        self.c = nn.Parameter(torch.randn(1, n_hid))\n",
    "        self.W = nn.Parameter(torch.randn(n_hid, n_vis))\n",
    "        \n",
    "        self.k = k\n",
    "        self.γ = γ\n",
    "        self.nu = nu\n",
    "        self.k = k\n",
    "        \n",
    "        self.Z = np.mean( np.power(train_data.sum(1), nu) )\n",
    "        \n",
    "        for (_, p) in self.named_parameters():\n",
    "            p.data.normal_(0, 0.02)\n",
    "            p.grad = p.data.clone()\n",
    "            \n",
    "    def beta(self, x):\n",
    "        return self.γ * (x.sum(1, keepdim=True)).pow(self.nu) / self.Z\n",
    "        \n",
    "    def visible_to_hidden(self, beta, v, mean=False):\n",
    "        p = torch.sigmoid(\n",
    "            beta * v @ self.W.data.T + beta * self.c.data\n",
    "        )\n",
    "        return p if mean else p.bernoulli()\n",
    "\n",
    "    def hidden_to_visible(self, beta, h, mean=False):\n",
    "        p = torch.sigmoid(\n",
    "            beta * h @ self.W.data + beta * self.b.data\n",
    "        )\n",
    "        return p if mean else p.bernoulli()\n",
    "    \n",
    "    def f_v(self, beta, v):\n",
    "        res = F.softplus(beta * v @ self.W.T + beta * self.c).sum(1).mean()\n",
    "        res += (beta * v @ self.b.T).mean()\n",
    "        return -res\n",
    "    \n",
    "    def forward(self, beta, v_data, v_gibbs):\n",
    "        return self.f_v(beta, v_data) - self.f_v(beta, v_gibbs)\n",
    "\n",
    "    def sample(self, beta, v_data):\n",
    "        v_gibbs = v_data.clone()\n",
    "        \n",
    "        for _ in range(self.k):\n",
    "            v_gibbs = (v_gibbs * 0.5).bernoulli()\n",
    "\n",
    "            h = self.visible_to_hidden(beta, v_gibbs)\n",
    "            v_gibbs = self.hidden_to_visible(beta, h)\n",
    "        return v_gibbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58081aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T23:52:20.192079Z",
     "start_time": "2025-05-16T23:52:20.189582Z"
    }
   },
   "source": [
    "# Prediction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978c312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:32:59.505513Z",
     "start_time": "2025-05-17T11:32:59.499160Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, method, data_in, data_out, metrics, samples_perc_per_epoch=1, batch_size=500):\n",
    "    metrics = deepcopy(metrics)\n",
    "    model.eval()\n",
    "    time_sum = 0\n",
    "    \n",
    "    for m in metrics:\n",
    "        m['score'] = []\n",
    "    \n",
    "    for batch in generate(batch_size=batch_size,\n",
    "                          device=device,\n",
    "                          data_in=data_in,\n",
    "                          data_out=data_out,\n",
    "                          samples_perc_per_epoch=samples_perc_per_epoch\n",
    "                         ):\n",
    "        \n",
    "        ratings_in_dev = batch.get_ratings_to_dev()\n",
    "        ratings_in = batch.get_ratings()\n",
    "        ratings_out = batch.get_ratings(is_out=True)\n",
    "        if (ratings_out.sum(1) < 1).sum() > 0:\n",
    "            ids = np.array(ratings_out.sum(1) > 0)[:,0]\n",
    "            ratings_out = ratings_out[ids]\n",
    "            ratings_in = ratings_in[ids]\n",
    "            ratings_in_dev = ratings_in_dev[torch.tensor(ids).to(device)]\n",
    "    \n",
    "        time_start = time.time()        \n",
    "        ratings_pred = method(model, ratings_in_dev).cpu().numpy()\n",
    "            \n",
    "        time_end = time.time()\n",
    "        time_sum += time_end - time_start\n",
    "            \n",
    "        if not (data_in is data_out):\n",
    "            ratings_pred[batch.get_ratings().nonzero()] = -np.inf\n",
    "            \n",
    "        for m in metrics:\n",
    "            m['score'].append(m['metric'](ratings_pred, ratings_out, k=m['k']))\n",
    "\n",
    "    for m in metrics:\n",
    "        m['score'] = np.concatenate(m['score']).mean()\n",
    "        \n",
    "    print(time_sum)\n",
    "    return [x['score'] for x in metrics]\n",
    "\n",
    "\n",
    "def gaussian_probit_approx(model, x):\n",
    "    beta = model.beta(x)\n",
    "    p = model.visible_to_hidden(beta, x, mean=True)\n",
    "    d = beta * p * (1 - p) * beta\n",
    "    cov = d @ model.W.data.pow(2)\n",
    "    B = (1 + cov * torch.pi / 8).sqrt()\n",
    "    return ((beta * p @ model.W.data + beta * model.b.data) / B)\n",
    "\n",
    "    \n",
    "def first_order_approx(model, x):\n",
    "    beta = model.beta(x)\n",
    "    h = model.visible_to_hidden(beta, x, mean=True)\n",
    "    return model.hidden_to_visible(beta, h, mean=True)\n",
    "\n",
    "\n",
    "def MC_approx(model, x, N):\n",
    "    beta = model.beta(x)\n",
    "    h = model.visible_to_hidden(beta, (x * 0.9).bernoulli())\n",
    "    ratings_pred = model.hidden_to_visible(beta, h, mean=True)\n",
    "    for _ in range(N):\n",
    "        h = model.visible_to_hidden(beta, (x * 0.9).bernoulli())\n",
    "        ratings_pred += model.hidden_to_visible(beta, h, mean=True)\n",
    "    return ratings_pred\n",
    "\n",
    "\n",
    "def density_based_pred(model, x):\n",
    "    beta = model.beta(x)\n",
    "    W, b, c = model.W.data, model.b.data, model.c.data\n",
    "    res = F.softplus( (beta * x @ W.T + beta * c)[:,None,:] + ((beta * torch.ones_like(x))[:,:,None] * W.T[None,:,:]) ).sum(dim=-1)\n",
    "    res -= F.softplus( (beta * x @ W.T + beta * c)[:,None,:] + ((beta * torch.zeros_like(x))[:,:,None] * W.T[None,:,:]) ).sum(dim=-1)\n",
    "    res += ((beta * torch.ones_like(x))[:,:,None] * b.T[None,:,:])[:,:,0]\n",
    "    res -= ((beta * torch.zeros_like(x))[:,:,None] * b.T[None,:,:])[:,:,0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503880",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009e45b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:33:07.645835Z",
     "start_time": "2025-05-17T11:32:59.506141Z"
    }
   },
   "outputs": [],
   "source": [
    "params['lr'] = 0.0005\n",
    "params['bs_max'] = 4096\n",
    "\n",
    "bs_min, bs_vel, bs_max = params['bs_min'], params['bs_vel'], params['bs_max']\n",
    "γ_start, γ_vel = params['γ_st %'], params['γ_vel']\n",
    "\n",
    "print(params)\n",
    "\n",
    "\n",
    "best_score = -np.inf\n",
    "best_epoch = -1\n",
    "valid_scores = []\n",
    "\n",
    "model_best = RBM(n_items, params['n_hid'], None, -params['-nu']).to(device)\n",
    "model      = RBM(n_items, params['n_hid'], None, -params['-nu']).to(device)\n",
    "opt = optim.Adam(model.parameters(), params['lr'])\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(params['n_epochs']):\n",
    "\n",
    "    batch_size = min(2**(int(epoch * bs_vel + np.log2(bs_min))), bs_max)\n",
    "    model.γ = 1 / (epoch * γ_vel + 2**γ_start)\n",
    "\n",
    "    for batch in generate(batch_size=batch_size, device=device, data_in=train_data, shuffle=True):\n",
    "        v_data = batch.get_ratings_to_dev()\n",
    "        beta = model.beta(v_data)\n",
    "        v_gibbs = model.sample(beta, v_data)\n",
    "        opt.zero_grad()\n",
    "        loss = model(beta, v_data, v_gibbs)\n",
    "        loss.backward()            \n",
    "        opt.step()\n",
    "\n",
    "\n",
    "    score = evaluate(model, gaussian_probit_approx, valid_in_data, valid_out_data, metrics, samples_perc_per_epoch=1)[0]\n",
    "    valid_scores.append(score)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_epoch = epoch\n",
    "\n",
    "        model_best.load_state_dict(deepcopy(model.state_dict()))\n",
    "        model_best.γ = model.γ\n",
    "\n",
    "    print(f'epoch {epoch} | valid ndcg@100: {score:.4f} | best: {best_score:.4f} | ' + \n",
    "          f'batch size: {batch_size} | ' +\n",
    "          f'temp: {1 / model.γ:.3f}')\n",
    "\n",
    "    if epoch - best_epoch > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0747dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T00:21:18.949251Z",
     "start_time": "2025-05-17T00:21:18.947758Z"
    }
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208beee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:33:07.647143Z",
     "start_time": "2025-05-17T11:33:07.647137Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('Gaussian-probit approx')\n",
    "final_scores = evaluate(model_best, gaussian_probit_approx, test_in_data, test_out_data, test_metrics)\n",
    "for metric, score in zip(test_metrics, final_scores):\n",
    "    print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")\n",
    "\n",
    "print('First-order approx')\n",
    "final_scores = evaluate(model_best, first_order_approx, test_in_data, test_out_data, test_metrics)\n",
    "for metric, score in zip(test_metrics, final_scores):\n",
    "    print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")\n",
    "\n",
    "print('MC approx, N=100')\n",
    "final_scores = evaluate(model_best, lambda model, x: MC_approx(model, x, 100), test_in_data, test_out_data, test_metrics)\n",
    "for metric, score in zip(test_metrics, final_scores):\n",
    "    print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")\n",
    "    \n",
    "print('MC approx, N=1000')\n",
    "final_scores = evaluate(model_best, lambda model, x: MC_approx(model, x, 1000), test_in_data, test_out_data, test_metrics)\n",
    "for metric, score in zip(test_metrics, final_scores):\n",
    "    print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")\n",
    "    \n",
    "print('Density-based prediction')\n",
    "final_scores = evaluate(model_best, density_based_pred, test_in_data, test_out_data, test_metrics, batch_size=5)\n",
    "for metric, score in zip(test_metrics, final_scores):\n",
    "    print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
